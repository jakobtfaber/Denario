Universal Gait Fingerprints: Learning Demographically-Adaptive, Frequency- and Location-Invariant Representations for Robust Step Counting in Free-Living

This paper proposes developing novel deep learning architectures (e.g., contrastive learning, meta-learning, or multi-task learning) to extract universal, low-dimensional representations of purposeful steps from wearable accelerometer data. The goal is for these "gait fingerprints" to be inherently invariant to variations in sampling frequency (100Hz vs. 25Hz) and sensor location (hip vs. wrist). Critically, the study will investigate how these learned representations are influenced by participant age and sex, aiming to develop demographically-adaptive models or identify common and unique gait signatures across groups. This approach aims to transcend the current need for sensor- and frequency-specific models, enabling highly generalizable and resource-efficient step counting algorithms that robustly perform across diverse wearable device configurations and user populations, thereby advancing personalized and scalable digital health solutions.